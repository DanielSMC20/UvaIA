{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "IMAGE_SIZE = 256\n",
    "BATCH_SIZE = 32\n",
    "CHANNELS = 3\n",
    "EPOCHS = 50\n",
    "\n",
    "n_classes = 4  \n",
    "input_shape = (IMAGE_SIZE, IMAGE_SIZE, CHANNELS)\n",
    "\n",
    "resize_and_rescale = tf.keras.Sequential([\n",
    "    layers.Resizing(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    layers.Rescaling(1.0/255)\n",
    "])\n",
    "\n",
    "data_argumentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    layers.RandomRotation(0.2),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=input_shape),\n",
    "    resize_and_rescale,\n",
    "    data_argumentation,\n",
    "    layers.Conv2D(32, (3,3), activation=\"relu\"),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Conv2D(64, (3,3), activation=\"relu\"),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Conv2D(128, (3,3), activation=\"relu\"),  # Reduce el número de filtros\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(n_classes, activation=\"softmax\"),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3251 images belonging to 4 classes.\n",
      "Found 3251 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "train_ds = train_datagen.flow_from_directory(\n",
    "    'PlantVillage',\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='sparse'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator()\n",
    "val_ds = val_datagen.flow_from_directory(\n",
    "    'PlantVillage',\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='sparse'\n",
    ")\n",
    "\n",
    "train_ds = tf.data.Dataset.from_generator(\n",
    "    lambda: train_ds,\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None, IMAGE_SIZE, IMAGE_SIZE, CHANNELS), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None,), dtype=tf.float32)\n",
    "    )\n",
    ").cache().shuffle(buffer_size=1000).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "\n",
    "val_ds = tf.data.Dataset.from_generator(\n",
    "    lambda: val_ds,\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None, IMAGE_SIZE, IMAGE_SIZE, CHANNELS), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None,), dtype=tf.float32)\n",
    "    )\n",
    ").cache().prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: {0: 0.8609639830508474, 1: 0.7341915085817525, 2: 2.3974926253687316, 3: 0.9439605110336817}\n"
     ]
    }
   ],
   "source": [
    "class_names = ['Grape___Black_rot', 'Grape___Esca_(Black_Measles)', 'Grape___healthy', 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)']\n",
    "class_counts = [944, 1107, 339, 861]\n",
    "class_weights = compute_class_weight('balanced', classes=np.arange(len(class_names)), y=np.repeat(np.arange(len(class_names)), class_counts))\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "print(\"Class Weights:\", class_weights)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3251 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import time\n",
    "\n",
    "# Parámetros\n",
    "IMAGE_SIZE = 256\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Crear un generador de datos sin aumento de datos\n",
    "simple_datagen = ImageDataGenerator()\n",
    "\n",
    "simple_ds = simple_datagen.flow_from_directory(\n",
    "    'PlantVillage',\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='sparse'\n",
    ")\n",
    "\n",
    "# Convertir a tf.data.Dataset y optimizar\n",
    "simple_ds = tf.data.Dataset.from_generator(\n",
    "    lambda: simple_ds,\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None, IMAGE_SIZE, IMAGE_SIZE, 3), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None,), dtype=tf.float32)\n",
    "    )\n",
    ").cache().shuffle(buffer_size=1000).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# Medir el tiempo por lote sin aumento de datos\n",
    "start_time = time.time()\n",
    "\n",
    "# Procesar un lote\n",
    "for images, labels in simple_ds.take(1):\n",
    "    pass\n",
    "\n",
    "end_time = time.time()\n",
    "time_per_batch_simple = end_time - start_time\n",
    "\n",
    "print(f\"Tiempo por lote sin aumento de datos: {time_per_batch_simple:.2f} segundos\")\n",
    "\n",
    "# Crear el generador de datos con aumento de datos\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "train_ds = train_datagen.flow_from_directory(\n",
    "    'PlantVillage',\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='sparse'\n",
    ")\n",
    "\n",
    "# Convertir a tf.data.Dataset y optimizar\n",
    "train_ds = tf.data.Dataset.from_generator(\n",
    "    lambda: train_ds,\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None, IMAGE_SIZE, IMAGE_SIZE, 3), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None,), dtype=tf.float32)\n",
    "    )\n",
    ").cache().shuffle(buffer_size=1000).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# Medir el tiempo por lote con aumento de datos\n",
    "start_time = time.time()\n",
    "\n",
    "# Procesar un lote\n",
    "for images, labels in train_ds.take(1):\n",
    "    pass\n",
    "\n",
    "end_time = time.time()\n",
    "time_per_batch_augmented = end_time - start_time\n",
    "\n",
    "print(f\"Tiempo por lote con aumento de datos: {time_per_batch_augmented:.2f} segundos\")\n",
    "\n",
    "num_batches = 0\n",
    "for _ in train_ds.take(10):  \n",
    "    num_batches += 1\n",
    "    print(f\"Lote {num_batches} procesado\")\n",
    "\n",
    "print(f\"Número de lotes en el conjunto de datos de entrenamiento (estimado): {num_batches * (len(train_ds) // 10)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_batches = 0\n",
    "for _ in train_ds.take(10):  \n",
    "    num_batches += 1\n",
    "    print(f\"Lote {num_batches} procesado\")\n",
    "\n",
    "print(f\"Número de lotes en el conjunto de datos de entrenamiento (estimado): {num_batches * (len(train_ds) // 10)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in train_ds.take(1):\n",
    "    print(f\"Forma de las imágenes: {images.shape}\")\n",
    "    print(f\"Forma de las etiquetas: {labels.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: {0: 0.8609639830508474, 1: 0.7341915085817525, 2: 2.3974926253687316, 3: 0.9439605110336817}\n",
      "Epoch 1/50\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_ds,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version = 2\n",
    "save_dir = r\"C:\\Users\\candy\\Documents\\Python\\PlantasEnf\\modelo\"  \n",
    "os.makedirs(save_dir, exist_ok=True)  \n",
    "model.save(os.path.join(save_dir, f\"{model_version}Prueba.keras\"))\n",
    "\n",
    "\n",
    "test_loss, test_acc = model.evaluate(val_ds)\n",
    "print(f\"Test Accuracy: {test_acc * 100:.2f}%\")\n",
    "\n",
    "def predict(model, img):\n",
    "    img_array = tf.expand_dims(img, 0)  # Crear un lote\n",
    "    predictions = model.predict(img_array)\n",
    "    predicted_class = class_names[np.argmax(predictions[0])]\n",
    "    confidence = 100 * np.max(predictions[0])\n",
    "    return predicted_class, confidence\n",
    "\n",
    "for images, labels in val_ds.take(1):\n",
    "    plt.figure(figsize=(10, 10))  # Ajustar el tamaño de la figura si es necesario\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        predicted_class, confidence = predict(model, images[i].numpy())\n",
    "        actual_class = class_names[int(labels[i])]\n",
    "        plt.title(f\"Actual: {actual_class}, \\n Enfermedad: {predicted_class}.\\n Confidence: {confidence:.2f}%\", fontsize=8)  # Reducir el tamaño de la fuente\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
